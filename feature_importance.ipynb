{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(json_file):\n",
    "    j = json.load(open(json_file))\n",
    "    settings = os.path.basename(json_file).replace('.json', '').split('_')\n",
    "    j['dist'] = settings[0]\n",
    "    j['uni_or_bi'] = settings[1]\n",
    "    j['vocab_size'] = int(settings[2])\n",
    "    j['softmax'] = True if settings[3] == 'softmax' else False\n",
    "    j['settings'] = settings\n",
    "    j['losses'] = []\n",
    "    if 'lstm' in settings:\n",
    "        j['model_type'] = 'lstm'\n",
    "    elif 'ffnn' in settings:\n",
    "        j['model_type'] = 'ffnn'\n",
    "    else:\n",
    "        j['model_type'] = 'trf'\n",
    "    if 'embd256' in settings:\n",
    "        j['embd_size'] = 256\n",
    "    else:\n",
    "        j['embd_size'] = 64\n",
    "    for i in range(len(j['train_losses'])):\n",
    "        j['losses'].extend(j['train_losses'][i])\n",
    "    del j['train_losses']\n",
    "    if 'val_losses' in j:\n",
    "        print(json_file)\n",
    "    return j\n",
    "\n",
    "json_files = [\n",
    "    os.path.join('results', x) for x in os.listdir('results') if x.endswith('.json')\n",
    "]\n",
    "\n",
    "jsons = [data(json_file) for json_file in json_files]\n",
    "\n",
    "test_set_perplexity = []\n",
    "entropy = []\n",
    "dist = []\n",
    "uni_or_bi = []\n",
    "vocab_size = []\n",
    "softmax = []\n",
    "model_type = []\n",
    "embd_size = []\n",
    "\n",
    "for j in jsons:\n",
    "    test_set_perplexity.append(min(j['test_set_perplexities']))\n",
    "    entropy.append(j['entropy'])\n",
    "    dist.append(j['dist'])\n",
    "    uni_or_bi.append(j['uni_or_bi'])\n",
    "    vocab_size.append(j['vocab_size'])\n",
    "    softmax.append(j['softmax'])\n",
    "    model_type.append(j['model_type'])\n",
    "    embd_size.append(j['embd_size'])\n",
    "    \n",
    "for i in range(len(entropy)):\n",
    "    if uni_or_bi[i] == 'bigrams':\n",
    "        entropy[i] = entropy[i] / 2\n",
    "    \n",
    "test_set_avg_cross_entropy = [math.log(x) for x in test_set_perplexity]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Test set perplexity': test_set_perplexity,\n",
    "    'Test set average cross-entropy': test_set_avg_cross_entropy,\n",
    "    'Entropy': entropy,\n",
    "    'Distribution': dist,\n",
    "    'Uni- or bigram': uni_or_bi,\n",
    "    'Vocab size': vocab_size,\n",
    "    'Softmax': softmax,\n",
    "    'Model type': model_type,\n",
    "    'Embedding size': embd_size\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df['Distribution'] = enc.fit_transform(df[['Distribution']])\n",
    "df['Uni- or bigram'] = enc.fit_transform(df[['Uni- or bigram']])\n",
    "df['Softmax'] = enc.fit_transform(df[['Softmax']])\n",
    "df['Model type'] = enc.fit_transform(df[['Model type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscale numerical columns\n",
    "df = df.apply(lambda x: (x - x.mean()) / x.std() if x.name not in ['Distribution', 'Uni- or bigram', 'Softmax', 'Model type'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                  \n",
      "==========================================================================================\n",
      "Dep. Variable:     Test set average cross-entropy   R-squared:                       0.999\n",
      "Model:                                        OLS   Adj. R-squared:                  0.999\n",
      "Method:                             Least Squares   F-statistic:                 3.657e+04\n",
      "Date:                            Tue, 17 Dec 2024   Prob (F-statistic):               0.00\n",
      "Time:                                    03:16:41   Log-Likelihood:                 671.89\n",
      "No. Observations:                             357   AIC:                            -1328.\n",
      "Df Residuals:                                 349   BIC:                            -1297.\n",
      "Df Model:                                       7                                         \n",
      "Covariance Type:                        nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             -0.0040      0.005     -0.808      0.420      -0.014       0.006\n",
      "Entropy            1.0031      0.003    306.817      0.000       0.997       1.010\n",
      "Distribution       0.0007      0.003      0.226      0.821      -0.005       0.006\n",
      "Uni- or bigram    -0.0054      0.004     -1.308      0.192      -0.014       0.003\n",
      "Vocab size        -0.0044      0.003     -1.334      0.183      -0.011       0.002\n",
      "Softmax            0.0158      0.005      3.362      0.001       0.007       0.025\n",
      "Model type         0.0010      0.003      0.340      0.734      -0.005       0.007\n",
      "Embedding size    -0.0001      0.002     -0.059      0.953      -0.004       0.004\n",
      "==============================================================================\n",
      "Omnibus:                       14.920   Durbin-Watson:                   0.535\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               35.258\n",
      "Skew:                          -0.045   Prob(JB):                     2.21e-08\n",
      "Kurtosis:                       4.537   Cond. No.                         5.73\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "reg = sm.OLS(\n",
    "    df['Test set average cross-entropy'],\n",
    "    sm.add_constant(df.drop(columns=['Test set average cross-entropy', 'Test set perplexity']))\n",
    ")\n",
    "res = reg.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const             4.197419929550139094942551309941e-01\n",
      "Entropy           0.000000000000000000000000000000e+00\n",
      "Distribution      8.211825717118829137675106721872e-01\n",
      "Uni- or bigram    1.916123778503435459708015287106e-01\n",
      "Vocab size        1.829894317952111826297567631627e-01\n",
      "Softmax           8.604078528685862913352733194472e-04\n",
      "Model type        7.337479533292512456910117180087e-01\n",
      "Embedding size    9.526113984556410230197798227891e-01\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "p_values = res.pvalues\n",
    "print(p_values.apply('{:.30e}'.format))  # Print with scientific notation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

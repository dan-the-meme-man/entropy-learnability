{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_attrs(list1, list2):\n",
    "    return [str(list1[i]) + ', ' + str(list2[i]) for i in range(len(list1))]\n",
    "\n",
    "def data(json_file):\n",
    "    j = json.load(open(json_file))\n",
    "    settings = os.path.basename(json_file).replace('.json', '').split('_')\n",
    "    j['dist'] = settings[0]\n",
    "    j['uni_or_bi'] = settings[1]\n",
    "    j['vocab_size'] = int(settings[2])\n",
    "    j['softmax'] = True if settings[3] == 'softmax' else False\n",
    "    j['settings'] = settings\n",
    "    j['losses'] = []\n",
    "    if 'lstm' in settings:\n",
    "        j['model_type'] = 'lstm'\n",
    "    elif 'ffnn' in settings:\n",
    "        j['model_type'] = 'ffnn'\n",
    "    else:\n",
    "        j['model_type'] = 'trf'\n",
    "    if 'embd256' in settings:\n",
    "        j['embd_size'] = 256\n",
    "    else:\n",
    "        j['embd_size'] = 64\n",
    "    for i in range(len(j['train_losses'])):\n",
    "        j['losses'].extend(j['train_losses'][i])\n",
    "    del j['train_losses']\n",
    "    del j['table']\n",
    "    if 'val_losses' in j:\n",
    "        print(json_file)\n",
    "    return j\n",
    "\n",
    "json_files = paths = glob.glob('results/u*.json') + glob.glob('results/m*.json') + glob.glob('results/n*.json')\n",
    "\n",
    "jsons = []\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        d = data(json_file)\n",
    "        jsons.append(d)\n",
    "    except:\n",
    "        print(json_file)\n",
    "\n",
    "test_set_perplexity = []\n",
    "entropy = []\n",
    "dist = []\n",
    "uni_or_bi = []\n",
    "vocab_size = []\n",
    "softmax = []\n",
    "model_type = []\n",
    "embd_size = []\n",
    "\n",
    "for j in jsons:\n",
    "    test_set_perplexity.append(min(j['test_set_perplexities']))\n",
    "    entropy.append(j['entropy'])\n",
    "    dist.append(j['dist'])\n",
    "    uni_or_bi.append(j['uni_or_bi'])\n",
    "    vocab_size.append(j['vocab_size'])\n",
    "    softmax.append(j['softmax'])\n",
    "    model_type.append(j['model_type'])\n",
    "    embd_size.append(j['embd_size'])\n",
    "    \n",
    "for i in range(len(entropy)):\n",
    "    if uni_or_bi[i] == 'bigrams':\n",
    "        entropy[i] = entropy[i] / 2\n",
    "    \n",
    "test_set_avg_cross_entropy = [math.log(x) for x in test_set_perplexity]\n",
    "\n",
    "df = {\n",
    "    'Test set perplexity': test_set_perplexity,\n",
    "    'Test set average cross-entropy': test_set_avg_cross_entropy,\n",
    "    'Entropy': entropy,\n",
    "    'Distribution': dist,\n",
    "    'Uni- or bigram': uni_or_bi,\n",
    "    'Vocab size': vocab_size,\n",
    "    'Softmax': softmax,\n",
    "    'Model type': model_type,\n",
    "    'Embedding size': embd_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# curve fitting\n",
    "def exponential(x, a, b, c):\n",
    "    return a * np.exp(b * x) + c\n",
    "\n",
    "def linear(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "x_ent = np.linspace(min(entropy), max(entropy), 100)\n",
    "\n",
    "ppl_vs_ent = curve_fit(exponential, entropy, test_set_perplexity)\n",
    "\n",
    "y_ppl = exponential(x_ent, *ppl_vs_ent[0])\n",
    "\n",
    "ce_vs_ent = curve_fit(linear, entropy, test_set_avg_cross_entropy)\n",
    "\n",
    "y_ce = linear(x_ent, *ce_vs_ent[0])\n",
    "\n",
    "ppl_fit = go.Scatter(\n",
    "    x=x_ent,\n",
    "    y=y_ppl,\n",
    "    mode='lines',\n",
    "    name=f'{ppl_vs_ent[0][0]:.2f} * exp({ppl_vs_ent[0][1]:.2f} * x) + {ppl_vs_ent[0][2]:.2f}'\n",
    ")\n",
    "\n",
    "ce_fit = go.Scatter(\n",
    "    x=x_ent,\n",
    "    y=y_ce,\n",
    "    mode='lines',\n",
    "    name=f'{ce_vs_ent[0][0]:.2f} * x + {ce_vs_ent[0][1]:.2f}'\n",
    ")\n",
    "\n",
    "y_equals_x = go.Scatter(\n",
    "    x=x_ent,\n",
    "    y=x_ent,\n",
    "    mode='lines',\n",
    "    name='Theoretical limit'\n",
    ")\n",
    "\n",
    "default_colors = plotly.colors.qualitative.Plotly\n",
    "next_color = default_colors[13 % len(default_colors)]\n",
    "ppl_fit.update(marker_color=next_color)\n",
    "ce_fit.update(marker_color=next_color)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall R^2: 0.9825107684138789\n"
     ]
    }
   ],
   "source": [
    "# R^2\n",
    "residuals = test_set_avg_cross_entropy - linear(np.array(entropy), *ce_vs_ent[0])\n",
    "ss_res = np.sum(residuals**2)\n",
    "ss_tot = np.sum((test_set_avg_cross_entropy - np.mean(test_set_avg_cross_entropy))**2)\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "print(f'Overall R^2: {r_squared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting options\n",
    "legend_dict = dict(\n",
    "    orientation='h',\n",
    "    y=-0.15,\n",
    ")\n",
    "\n",
    "marker_dict = dict(\n",
    "    size=12,\n",
    "    opacity=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set perplexity',\n",
    "    title='Test set perplexity vs. entropy',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set perplexity', 'color': 'Uni- or bigram'},\n",
    "    color=uni_or_bi,\n",
    "    hover_data={'Vocab size': True, 'Softmax': True, 'Distribution': True, 'Model type': True, 'Embedding size': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ppl_fit)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/uni_or_bi.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set perplexity',\n",
    "    title='Test set perplexity vs. entropy',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set perplexity', 'color': 'Vocab size'},\n",
    "    color=[str(x) for x in vocab_size],\n",
    "    category_orders={'color': reversed([str(x) for x in sorted(vocab_size)])},\n",
    "    hover_data={'Uni- or bigram': True, 'Softmax': True, 'Distribution': True, 'Model type': True, 'Embedding size': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ppl_fit)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/vocab.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set perplexity',\n",
    "    title='Test set perplexity vs. entropy',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set perplexity', 'color': 'Uni- or bigram and distribution'},\n",
    "    color=combine_attrs(uni_or_bi, dist),\n",
    "    hover_data={'Vocab size': True, 'Softmax': True, 'Model type': True, 'Embedding size': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ppl_fit)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/uni_or_bi_dist.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set perplexity',\n",
    "    title='Test set perplexity vs. entropy',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set perplexity', 'color': 'Model type'},\n",
    "    color='Model type',\n",
    "    hover_data={'Vocab size': True, 'Softmax': True, 'Uni- or bigram': True, 'Distribution': True, 'Embedding size': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ppl_fit)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/model_type.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set perplexity',\n",
    "    title='Test set perplexity vs. entropy',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set perplexity', 'color': 'Embedding size'},\n",
    "    color=[str(x) for x in embd_size],\n",
    "    hover_data={'Vocab size': True, 'Softmax': True, 'Uni- or bigram': True, 'Distribution': True, 'Model type': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ppl_fit)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/embd_size.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set perplexity',\n",
    "    title='Test set perplexity vs. entropy',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set perplexity', 'color': 'Softmax'},\n",
    "    color='Softmax',\n",
    "    hover_data={'Vocab size': True, 'Uni- or bigram': True, 'Distribution': True, 'Model type': True, 'Embedding size': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ppl_fit)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/softmax.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set average cross-entropy',\n",
    "    title=f'Test set average cross-entropy vs. entropy, R^2={r_squared:.4f}',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set average cross-entropy', 'color': 'Uni- or bigram'},\n",
    "    color='Uni- or bigram',\n",
    "    hover_data={'Vocab size': True, 'Softmax': True, 'Distribution': True, 'Model type': True, 'Embedding size': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ce_fit)\n",
    "fig.add_trace(y_equals_x)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/uni_or_bi_ce.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set average cross-entropy',\n",
    "    title=f'Test set average cross-entropy vs. entropy, R^2={r_squared:.4f}',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set average cross-entropy', 'color': 'Vocab size'},\n",
    "    color=[str(x) for x in vocab_size],\n",
    "    category_orders={'color': reversed([str(x) for x in sorted(vocab_size)])},\n",
    "    hover_data={'Uni- or bigram': True, 'Softmax': True, 'Distribution': True, 'Model type': True, 'Embedding size': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ce_fit)\n",
    "fig.add_trace(y_equals_x)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/vocab_ce.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set average cross-entropy',\n",
    "    title=f'Test set average cross-entropy vs. entropy, R^2={r_squared:.4f}',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set average cross-entropy', 'color': 'Uni- or bigram and distribution'},\n",
    "    color=combine_attrs(uni_or_bi, dist),\n",
    "    hover_data={'Vocab size': True, 'Softmax': True, 'Model type': True, 'Embedding size': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ce_fit)\n",
    "fig.add_trace(y_equals_x)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/uni_or_bi_dist_ce.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set average cross-entropy',\n",
    "    title=f'Test set average cross-entropy vs. entropy, R^2={r_squared:.4f}',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set average cross-entropy', 'color': 'Model type'},\n",
    "    color='Model type',\n",
    "    hover_data={'Vocab size': True, 'Softmax': True, 'Uni- or bigram': True, 'Distribution': True, 'Embedding size': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ce_fit)\n",
    "fig.add_trace(y_equals_x)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/model_type_ce.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set average cross-entropy',\n",
    "    title=f'Test set average cross-entropy vs. entropy, R^2={r_squared:.4f}',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set average cross-entropy', 'color': 'Embedding size'},\n",
    "    color=[str(x) for x in embd_size],\n",
    "    hover_data={'Vocab size': True, 'Softmax': True, 'Uni- or bigram': True, 'Distribution': True, 'Model type': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ce_fit)\n",
    "fig.add_trace(y_equals_x)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/embd_size_ce.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Entropy',\n",
    "    y='Test set average cross-entropy',\n",
    "    title=f'Test set average cross-entropy vs. entropy, R^2={r_squared:.4f}',\n",
    "    labels={'x': 'Entropy', 'y': 'Test set average cross-entropy', 'color': 'Softmax'},\n",
    "    color='Softmax',\n",
    "    hover_data={'Vocab size': True, 'Embedding size': True, 'Uni- or bigram': True, 'Distribution': True, 'Model type': True},\n",
    ")\n",
    "fig.update_layout(legend=legend_dict)\n",
    "fig.update_traces(marker=marker_dict)\n",
    "fig.add_trace(ce_fit)\n",
    "fig.add_trace(y_equals_x)\n",
    "fig.data = fig.data[::-1]\n",
    "fig.write_html('plots/softmax_ce.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, j in enumerate(jsons):\n",
    "#     plt.figure(figsize=(10, 1))\n",
    "#     data = j['losses']\n",
    "#     plt.scatter(range(len(data)), data, s=0.1)\n",
    "#     plt.title(f'{j[\"settings\"]}')\n",
    "#     plt.xticks(range(0, len(data)+1, 2000), labels=[f'{int(x/1000)}K' for x in range(0, len(data)+1, 2000)])\n",
    "#     plt.xlabel('Training steps')\n",
    "#     plt.ylabel('Cross-entropy')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
